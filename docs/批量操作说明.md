# 批量操作说明 (v1.9.0)

## 概述

v1.9.0 引入了批量操作增强，提供并发处理、进度追踪、断点续传和批量回滚功能。

## 核心功能

### 1. 并发处理

使用多线程并发处理文件，大幅提升处理速度。

**特性：**
- ✅ 多线程并发（默认4线程）
- ✅ 智能任务调度
- ✅ 资源限制控制
- ✅ 错误隔离

**性能提升：**
- 单线程：100个文件 ~300秒
- 4线程：100个文件 ~75秒
- 加速比：4倍

**使用方法：**
```python
from batch_processor import ConcurrentProcessor

processor = ConcurrentProcessor(max_workers=4)

def process_file(file):
    # 处理单个文件
    return result

items = ['file1.mp4', 'file2.mp4', ...]
result = processor.process_batch(items, process_file)

print(f"成功: {result['stats']['completed']}")
print(f"失败: {result['stats']['failed']}")
```

### 2. 进度追踪

实时追踪处理进度，显示预计剩余时间。

**特性：**
- ✅ 实时进度百分比
- ✅ 成功/失败计数
- ✅ 预计剩余时间（ETA）
- ✅ 成功率统计
- ✅ 失败项目记录

**使用方法：**
```python
from batch_processor import ProgressTracker

tracker = ProgressTracker(total=100)

for item in items:
    success = process_item(item)
    tracker.update(success=success, item=item)
    
    # 获取统计信息
    stats = tracker.get_stats()
    print(f"进度: {stats['progress']*100:.1f}%")
    print(f"ETA: {stats['eta']:.1f}秒")
```

### 3. 断点续传

操作中断后可以从断点处继续，避免重复处理。

**特性：**
- ✅ 自动保存检查点
- ✅ 从中断处继续
- ✅ 检查点管理
- ✅ 自动清理

**使用方法：**
```python
from batch_processor import CheckpointManager

manager = CheckpointManager()

# 保存检查点
state = {
    'processed_items': [...],
    'remaining_items': [...],
    'progress': 0.6
}
manager.save_checkpoint('operation_001', state)

# 加载检查点
state = manager.load_checkpoint('operation_001')
if state:
    # 从断点继续
    remaining = state['remaining_items']
else:
    # 开始新操作
    remaining = all_items

# 完成后删除检查点
manager.delete_checkpoint('operation_001')
```

### 4. 批量回滚

记录操作历史，支持一键回滚。

**特性：**
- ✅ 操作历史记录
- ✅ 一键回滚
- ✅ 选择性回滚
- ✅ 回滚状态追踪

**使用方法：**
```python
from batch_processor import RollbackManager

manager = RollbackManager()

# 记录操作
operation = {
    'type': 'file_move',
    'files': [
        {'from': '/path/a.txt', 'to': '/path/b.txt'}
    ]
}
manager.record_operation('op_001', operation)

# 回滚操作
def rollback_handler(op):
    # 执行回滚逻辑
    for file in op['files']:
        move_file(file['to'], file['from'])
    return True

success = manager.rollback('op_001', rollback_handler)
```

## 完整示例

### 示例1：并发文件处理

```python
from batch_processor import ConcurrentProcessor, ProgressTracker

def process_file(filepath):
    """处理单个文件"""
    # 你的处理逻辑
    return result

# 创建处理器
processor = ConcurrentProcessor(max_workers=4)

# 文件列表
files = ['file1.mp4', 'file2.mp4', ...]

# 进度回调
def progress_callback(stats):
    print(f"进度: {stats['progress']*100:.0f}% | "
          f"完成: {stats['completed']} | "
          f"失败: {stats['failed']} | "
          f"ETA: {stats['eta']:.1f}秒")

# 批量处理
result = processor.process_batch(files, process_file, progress_callback)

# 查看结果
print(f"总计: {result['stats']['total']}")
print(f"成功: {result['stats']['completed']}")
print(f"失败: {result['stats']['failed']}")
print(f"成功率: {result['stats']['success_rate']*100:.1f}%")

# 关闭处理器
processor.shutdown()
```

### 示例2：断点续传

```python
from batch_processor import ConcurrentProcessor, CheckpointManager

processor = ConcurrentProcessor(max_workers=4)
checkpoint_mgr = CheckpointManager()

operation_id = "batch_process_001"
all_items = [...]  # 所有要处理的项目

# 检查断点
checkpoint = checkpoint_mgr.load_checkpoint(operation_id)
if checkpoint:
    print(f"从断点继续（进度: {checkpoint['progress']*100:.0f}%）")
    processed = checkpoint['processed_items']
    remaining = checkpoint['remaining_items']
else:
    print("开始新操作")
    processed = []
    remaining = all_items

try:
    # 处理剩余项目
    result = processor.process_batch(remaining, process_item)
    processed.extend([r['item'] for r in result['results'] if r['success']])
    
    print(f"处理完成: {len(processed)}/{len(all_items)}")
    
    # 删除检查点
    checkpoint_mgr.delete_checkpoint(operation_id)
    
except KeyboardInterrupt:
    print("操作中断，保存断点...")
    
    # 保存断点
    state = {
        'processed_items': processed,
        'remaining_items': [item for item in all_items if item not in processed],
        'progress': len(processed) / len(all_items)
    }
    checkpoint_mgr.save_checkpoint(operation_id, state)
    print(f"已保存断点（进度: {state['progress']*100:.0f}%）")

processor.shutdown()
```

### 示例3：批量回滚

```python
from batch_processor import RollbackManager
import shutil

manager = RollbackManager()

# 批量移动文件
def batch_move_files(files):
    operation_id = f"move_{int(time.time())}"
    
    # 记录操作
    operation = {
        'type': 'file_move',
        'files': []
    }
    
    for src, dst in files:
        shutil.move(src, dst)
        operation['files'].append({'from': src, 'to': dst})
    
    # 保存操作记录
    manager.record_operation(operation_id, operation)
    
    return operation_id

# 执行操作
files = [
    ('/path/a.txt', '/path/b.txt'),
    ('/path/c.txt', '/path/d.txt')
]
operation_id = batch_move_files(files)

# 如果需要回滚
def rollback_move(op):
    """回滚文件移动"""
    for file in op['files']:
        shutil.move(file['to'], file['from'])
    return True

# 执行回滚
success = manager.rollback(operation_id, rollback_move)
if success:
    print("回滚成功")
```

## 配置选项

### 并发数配置

```python
# 默认4线程
processor = ConcurrentProcessor(max_workers=4)

# 根据CPU核心数自动配置
import os
max_workers = os.cpu_count() or 4
processor = ConcurrentProcessor(max_workers=max_workers)

# 低配置设备使用2线程
processor = ConcurrentProcessor(max_workers=2)
```

### 检查点目录

```python
# 默认目录
manager = CheckpointManager()  # .checkpoints/

# 自定义目录
manager = CheckpointManager(checkpoint_dir='/path/to/checkpoints')
```

### 回滚历史目录

```python
# 默认目录
manager = RollbackManager()  # .rollback_history/

# 自定义目录
manager = RollbackManager(history_dir='/path/to/history')
```

## 性能优化建议

1. **合理设置并发数**
   - CPU密集型：并发数 = CPU核心数
   - IO密集型：并发数 = CPU核心数 * 2
   - 网络操作：并发数 = 4-8

2. **定期清理检查点**
   - 完成后立即删除检查点
   - 定期清理过期检查点

3. **控制内存使用**
   - 大文件处理时减少并发数
   - 使用流式处理

4. **错误处理**
   - 记录失败项目
   - 提供重试机制

## 常见问题

**Q: 并发处理会不会导致文件冲突？**  
A: 不会，每个线程处理独立的文件

**Q: 断点续传的检查点会占用多少空间？**  
A: 通常< 1MB，只保存元数据

**Q: 回滚操作是否可逆？**  
A: 回滚后不能再次回滚，但可以重新执行原操作

**Q: 如何查看所有可回滚的操作？**  
A: 使用 `manager.list_operations(rollback_available_only=True)`

## 更新日志

详见 `CHANGELOG-v1.9.0.md`
